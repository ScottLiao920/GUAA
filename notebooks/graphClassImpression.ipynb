{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.io as sio\n",
    "import argparse\n",
    "from modules.models import Model"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2483/958822752.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1609636071631,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "2tAIbSHkZ6ce",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# ! conda install -y pytorch==1.5.0 torchvision==0.6.0 cudatoolkit=10.1 -c pytorch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# ! pip3 install torch-scatter==2.0.4 -f https://pytorch-geometric.com/whl/torch-1.5.0+cu101.html\n",
    "# ! pip3 install torch-sparse==0.6.4 -f https://pytorch-geometric.com/whl/torch-1.5.0+cu101.html\n",
    "# ! pip3 install torch-cluster==1.5.4 -f https://pytorch-geometric.com/whl/torch-1.5.0+cu101.html\n",
    "# ! pip3 install torch-spline-conv==1.2.0 -f https://pytorch-geometric.com/whl/torch-1.5.0+cu101.html\n",
    "# ! pip3 install torch-geometric==1.5.0"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1609636127352,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "HASPpv4rZ6cp",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# ! python -V"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch_geometric as geo\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"#, 1, 2\"\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(out, color):\n",
    "    z = TSNE(n_components=2).fit_transform(out.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "/home/twp/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_sparse/_version.so: undefined symbol: _ZN3c105ErrorC1ENS_14SourceLocationERKSs",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b7d4f2f85d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_geometric/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_geometric/nn/data_parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0min_memory_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataListLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m from torch_geometric.utils import (contains_isolated_nodes,\n\u001b[1;32m      9\u001b[0m                                    contains_self_loops, is_undirected)\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m ]:\n\u001b[1;32m     12\u001b[0m     torch.ops.load_library(importlib.machinery.PathFinder().find_spec(\n\u001b[0;32m---> 13\u001b[0;31m         library, [osp.dirname(__file__)]).origin)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/guaa/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /home/twp/anaconda3/envs/guaa/lib/python3.6/site-packages/torch_sparse/_version.so: undefined symbol: _ZN3c105ErrorC1ENS_14SourceLocationERKSs"
     ]
    }
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 6520,
     "status": "ok",
     "timestamp": 1609636136457,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "97cuH1zCaUdL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# torch.distributed.init_process_group(backend='nccl', init_method='tcp://localhost:23456', rank=0, world_size=1)"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1609636818550,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "bb_P5WkgZ6cq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dataset_name = 'PROTEINS'"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1609636818552,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "P20kewf-Z6cq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def getDataset(root, name, transform):\n",
    "    if name.lower() in ['cora', 'pubmed', 'citeseer']:\n",
    "        dataset = geo.datasets.Planetoid(root=root, name=name, transform=transform)\n",
    "    elif name.lower() in ['mutag', 'imdb-binary', 'ethanol', 'proteins']:\n",
    "        dataset =geo.datasets.TUDataset(root=root, name=name, transform=transform,use_node_attr=True)\n",
    "    else:\n",
    "        raise NotImplementedError(\"{} not supported!\".format(name))\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1609636819878,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "673ohvVLZ6cq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "dataset = getDataset('data', dataset_name, None)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1337,
     "status": "ok",
     "timestamp": 1609636821718,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "iLJVY818Z6cr",
    "outputId": "7be74187-b61f-46f4-e41b-8cd74344e981"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Dataset: PROTEINS(1113):\n",
      "======================\n",
      "Number of graphs: 1113\n",
      "Number of features: 4\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 162], x=[42, 4], y=[1])\n",
      "===========================================================================================================\n",
      "Number of nodes: 42\n",
      "Number of edges: 162\n",
      "Average node degree: 3.86\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1609636822071,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "12A5D_prZ6cs",
    "outputId": "22f893e2-515c-4802-e0bc-38d21c92a68d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "if dataset_name == 'PROTEINS':\n",
    "    print(\"USING Hierarchical Graph Pooling with Structure Learning\")\n",
    "    with open('config-{}.pickle'.format(dataset_name), 'rb') as handle:\n",
    "        args = pickle.load(handle)\n",
    "    args.device='cpu'\n",
    "    print(args)\n",
    "    num_training = int(len(dataset) * 0.8)\n",
    "    num_val = int(len(dataset) * 0.1)\n",
    "    num_test = len(dataset) - (num_training + num_val)\n",
    "    training_set, validation_set, test_set = random_split(dataset, [num_training, num_val, num_test])\n",
    "    \n",
    "    train_loader = geo.data.DataLoader(training_set, batch_size=args.batch_size, shuffle=True)\n",
    "    val_loader = geo.data.DataLoader(validation_set, batch_size=args.batch_size, shuffle=False)\n",
    "    test_loader = geo.data.DataLoader(test_set, batch_size=args.batch_size, shuffle=False)\n",
    "    try:\n",
    "        model = Model(args).to(args.device)\n",
    "    except RuntimeError:\n",
    "        args.device = 'cpu'\n",
    "        model = Model(args).to(args.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    \n",
    "    def train():\n",
    "        min_loss = 1e10\n",
    "        patience_cnt = 0\n",
    "        val_loss_values = []\n",
    "        best_epoch = 0\n",
    "\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        for epoch in range(args.epochs):\n",
    "            loss_train = 0.0\n",
    "            correct = 0\n",
    "            for i, data in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                data = data.to(args.device)\n",
    "                out = model(data)\n",
    "                loss = F.nll_loss(out, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_train += loss.item()\n",
    "                pred = out.max(dim=1)[1]\n",
    "                correct += pred.eq(data.y).sum().item()\n",
    "            acc_train = correct / len(train_loader.dataset)\n",
    "            acc_val, loss_val = compute_test(val_loader)\n",
    "            print('Epoch: {:04d}'.format(epoch + 1), 'loss_train: {:.6f}'.format(loss_train),\n",
    "                  'acc_train: {:.6f}'.format(acc_train), 'loss_val: {:.6f}'.format(loss_val),\n",
    "                  'acc_val: {:.6f}'.format(acc_val), 'time: {:.6f}s'.format(time.time() - t))\n",
    "\n",
    "            val_loss_values.append(loss_val)\n",
    "            torch.save(model.state_dict(), 'models/PROTEINS/{}.pth'.format(epoch))\n",
    "            if val_loss_values[-1] < min_loss:\n",
    "                min_loss = val_loss_values[-1]\n",
    "                best_epoch = epoch\n",
    "                patience_cnt = 0\n",
    "            else:\n",
    "                patience_cnt += 1\n",
    "\n",
    "            if patience_cnt == args.patience:\n",
    "                break\n",
    "\n",
    "            files = glob.glob('models/PROTEINS/*.pth')\n",
    "            for f in files:\n",
    "                epoch_nb = int(f.split('/')[-1].split('.')[0])\n",
    "                if epoch_nb < best_epoch:\n",
    "                    os.remove(f)\n",
    "\n",
    "        files = glob.glob('models/PROTEINS/*.pth')\n",
    "        for f in files:\n",
    "            epoch_nb = int(f.split('/')[-1].split('.')[0])\n",
    "            if epoch_nb > best_epoch:\n",
    "                os.remove(f)\n",
    "        print('Optimization Finished! Total time elapsed: {:.6f}'.format(time.time() - t))\n",
    "\n",
    "        return best_epoch\n",
    "\n",
    "\n",
    "    def compute_test(loader):\n",
    "        model.eval()\n",
    "        correct = 0.0\n",
    "        loss_test = 0.0\n",
    "        for data in loader:\n",
    "            data = data.to(args.device)\n",
    "            out = model(data)\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            loss_test += F.nll_loss(out, data.y).item()\n",
    "        return correct / len(loader.dataset), loss_test\n",
    "    \n",
    "else:\n",
    "    class GCN_node(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels):\n",
    "            super(GCN_node, self).__init__()\n",
    "            torch.manual_seed(0)\n",
    "            self.conv1 = geo.nn.GCNConv(dataset.num_features, hidden_channels)\n",
    "            self.conv2 = geo.nn.GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = x.relu()\n",
    "            x = nn.functional.dropout(x, p=0.5, training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "\n",
    "    class GCN_graph(torch.nn.Module):\n",
    "        def __init__(self, hidden_channels):\n",
    "            super(GCN_graph, self).__init__()\n",
    "            torch.manual_seed(0)\n",
    "            self.conv1 = geo.nn.GCNConv(dataset.num_node_features, hidden_channels)\n",
    "            self.conv2 = geo.nn.GCNConv(hidden_channels, hidden_channels)\n",
    "            self.conv3 = geo.nn.GCNConv(hidden_channels, hidden_channels)\n",
    "            self.lin = nn.Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "        def forward(self, x, edge_index, batch):\n",
    "            # not using edge attributes as it's hard to fake\n",
    "            # 1. Obtain node embeddings \n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = x.relu()\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = x.relu()\n",
    "            x = self.conv3(x, edge_index)\n",
    "\n",
    "            # 2. Readout layer\n",
    "            x = geo.nn.global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "            # 3. Apply a final classifier\n",
    "            x = nn.functional.dropout(x, p=0.5, training=self.training)\n",
    "            x = self.lin(x)\n",
    "\n",
    "            return x\n",
    "    device = torch.device('cuda')\n",
    "    victim_model = GCN_graph(hidden_channels=512).to(device)\n",
    "    optimizer = torch.optim.Adam(victim_model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train():\n",
    "        victim_model.train()\n",
    "\n",
    "        for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "            data = data.to(device)\n",
    "            out = victim_model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    def test(loader):\n",
    "        victim_model.eval()\n",
    "        correct = 0\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            data = data.to(device)\n",
    "            out = victim_model(data.x, data.edge_index, data.batch)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USING Hierarchical Graph Pooling with Structure Learning\n",
      "Namespace(batch_size=512, dataset='PROTEINS', device='cpu', dropout_ratio=0.0, epochs=1000, lamb=1.0, lr=0.001, nhid=128, num_classes=2, num_features=4, patience=100, pooling_ratio=0.5, sample_neighbor=True, seed=777, sparse_attention=True, structure_learning=True, weight_decay=0.001)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "trained = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "args#.lr = 5e-5"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Namespace(batch_size=512, dataset='PROTEINS', device='cpu', dropout_ratio=0.0, epochs=1000, lamb=1.0, lr=0.001, nhid=128, num_classes=2, num_features=4, patience=100, pooling_ratio=0.5, sample_neighbor=True, seed=777, sparse_attention=True, structure_learning=True, weight_decay=0.001)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "if not trained:\n",
    "    if dataset_name != \"PROTEINS\":\n",
    "        for epoch in range(1, 501):\n",
    "            train()\n",
    "            if epoch % 20 == 0:\n",
    "                train_acc = test(train_loader)\n",
    "                test_acc = test(test_loader)\n",
    "                print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    else:\n",
    "        # Model training\n",
    "        best_model = train()\n",
    "        # Restore best model for test set\n",
    "        model.load_state_dict(torch.load('models/PROTEINS/{}.pth'.format(best_model)))\n",
    "        test_acc, test_loss = compute_test(test_loader)\n",
    "        print('Test set results, loss = {:.6f}, accuracy = {:.6f}'.format(test_loss, test_acc))\n",
    "else:\n",
    "    model.load_state_dict(torch.load('models/PROTEINS/220.pth', map_location=args.device))\n",
    "    model.eval()\n",
    "    test_acc, test_loss = compute_test(test_loader)\n",
    "    print('Test set results, loss = {:.6f}, accuracy = {:.6f}'.format(test_loss, test_acc))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test set results, loss = 0.392510, accuracy = 0.830357\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16573,
     "status": "ok",
     "timestamp": 1609637184345,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "_KARF-SWZ6ct",
    "outputId": "974cfe08-ef00-4350-950a-eae22bafeb06",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "test_acc, _ = compute_test(test_loader)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 0.8304\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1609637251659,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "lKiooPMgZ6cu",
    "outputId": "975b8fc9-3605-4d7f-e893-65cf976cadec"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def idx2adj(data):\n",
    "    device = data.edge_index.device\n",
    "    edge_index = torch.zeros(size=(data.num_nodes, data.num_nodes), device=device)\n",
    "    for i in range(data.edge_index.shape[1]):\n",
    "        edge_index[data.edge_index[0][i]][data.edge_index[1][i]] = 1\n",
    "    return edge_index"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1609637260664,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "hnDKZieye8Op"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def adj2idx(edge_index):\n",
    "    assert edge_index.shape[0] == edge_index.shape[1]\n",
    "    tmp = []\n",
    "    for i in range(edge_index.shape[0]):\n",
    "        for j in range(edge_index.shape[0]):\n",
    "            if edge_index[i][j] == 1:\n",
    "                tmp.append([i, j])\n",
    "    return torch.Tensor(tmp).permute(1,0).to(edge_index.device)"
   ],
   "outputs": [],
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1609637268141,
     "user": {
      "displayName": "Chang Liao",
      "photoUrl": "",
      "userId": "06811123036923729114"
     },
     "user_tz": -480
    },
    "id": "YyT_icnzf4pG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## random initialize an edge index, zero-initialize node features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def getNodes(n):    \n",
    "    # node features are 4D vectors, the first dimension means the van de wall force and the next 3 are one-hot-encoded category\n",
    "    tmp = torch.cat((torch.randint(-500, 800, (n,1), device=args.device),\n",
    "                     torch.nn.functional.one_hot(torch.randint(0, 3, (n,), device=args.device), num_classes=3)), dim=1)\n",
    "    return tmp.float().clone()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## explore the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "cnt = {\n",
    "    '0': {},\n",
    "    '1': {},\n",
    "    '2': {},\n",
    "    '3': {}\n",
    "}\n",
    "for i in range(len(dataset)):\n",
    "    for j in range(dataset[i].x.shape[0]):\n",
    "        for k in range(4):\n",
    "            try:\n",
    "                cnt[str(k)][str(dataset[i].x[j, k].item())] += 1\n",
    "            except KeyError:\n",
    "                cnt[str(k)][str(dataset[i].x[j, k].item())] = 1\n",
    "#             print(sum([dataset[i].x[j, idx].item() for idx in range(1,4)]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "dataset[i].x[j, k].item()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "max([float(i) for i in list(cnt['0'].keys())])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "798.0"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "min([float(i) for i in list(cnt['0'].keys())])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-538.0"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load generated surrogate data to torch geometric dataset (not used)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "class surrogateData(geo.data.Dataset):\n",
    "    def __init__(self, dataList):\n",
    "        super().__init__()\n",
    "        self.data = dataList\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        self.data[index].x.long\n",
    "        return self.data[index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## freeze weights in victim model, the model will return node embedding after freezing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    print(param.requires_grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def getOutput(embed):\n",
    "    outp = F.relu(model.lin1(embed))\n",
    "    outp = F.dropout(outp, p=model.dropout_ratio, training=model.training)\n",
    "    outp = F.relu(model.lin2(outp))\n",
    "    outp = F.dropout(outp, p=model.dropout_ratio, training=model.training)\n",
    "    outp = F.log_softmax(model.lin3(outp), dim=-1)\n",
    "    return outp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregate previous algos together"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for every class, generate certain amount of class imporessions\n",
    "for cur_class in range(dataset.num_classes):\n",
    "    # update class impressions individually\n",
    "    for idx in range(500):\n",
    "        \n",
    "        # create an random adjacency matrix for given nodes & labels\n",
    "        num_nodes = random.randint(1, 600)\n",
    "        sample = geo.data.Batch()\n",
    "        adv_adj = torch.zeros(size=(num_nodes, num_nodes), device=args.device).bool()\n",
    "        for i in range(num_nodes):\n",
    "            adv_adj[i, i:].random_(0, 2)\n",
    "        adv_adj = adv_adj.int()\n",
    "        if adv_adj.sum().item() == 0: \n",
    "            idx -= 1\n",
    "            continue\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i, num_nodes):\n",
    "                adv_adj[j, i] = adv_adj[i, j]\n",
    "        sample.edge_index = adj2idx(adv_adj).long()\n",
    "        sample.x = getNodes(num_nodes)\n",
    "        sample.x.requires_grad_()\n",
    "#         sample.to(args.device)\n",
    "        \n",
    "        cl_optim = torch.optim.Adam([sample.x], lr=0.1)\n",
    "        cur_pred = model(sample)\n",
    "        cur_pred = getOutput(cur_pred)\n",
    "        cur_tar = random.uniform(0.55, 0.99)\n",
    "        cnt = 0\n",
    "        while F.softmax(cur_pred)[:, cur_class].item() < cur_tar and cnt < 5000: # cur_tar:\n",
    "            cl_optim.zero_grad()\n",
    "            cur_pred = getOutput(model(sample))\n",
    "            # loss = cl_lossfunc(cur_pred, cur_class)\n",
    "            # loss = dif_trans_lossfunc(loaded_model, cls_impr, cur_class)\n",
    "            loss = F.nll_loss(cur_pred, torch.Tensor([cur_class]).long().to(args.device))\n",
    "            loss.backward()\n",
    "            cl_optim.step()\n",
    "            if cnt % 500 == 0:\n",
    "                print(sample.x.grad.sum())\n",
    "                print('{} |　Epoch {} | Target Class {} | Current Logits for target class {}'.format(\n",
    "                    idx, cnt, cur_class, F.softmax(cur_pred)[0,cur_class].item()))\n",
    "            cnt += 1\n",
    "            with torch.no_grad():\n",
    "                sample.x.clamp_(-500, 600)\n",
    "#             print(F.softmax(cur_pred), F.softmax(cur_pred)[:, cur_class], cur_tar)\n",
    "        torch.save(sample, os.path.join('data', dataset_name, 'classImpression', str(cur_class), '{}.pt'.format(idx)))\n",
    "        print('Epoch {} | Target Class {} | Current Logits for target class {}'.format(\n",
    "                    cnt, cur_class, F.softmax(cur_pred)[0,cur_class].item()))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-7.0770)\n",
      "3 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.00018038782582152635\n",
      "Epoch 14 | Target Class 0 | Current Logits for target class 0.8888623118400574\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-2.9774)\n",
      "13 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.5344312191009521\n",
      "Epoch 2 | Target Class 0 | Current Logits for target class 0.7224118113517761\n",
      "tensor(-3.5846)\n",
      "14 |　Epoch 0 | Target Class 0 | Current Logits for target class 3.164360652121176e-22\n",
      "Epoch 100 | Target Class 0 | Current Logits for target class 0.6979009509086609\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 0.9981862902641296\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-7.4304)\n",
      "49 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.005685723386704922\n",
      "Epoch 2 | Target Class 0 | Current Logits for target class 0.9999997615814209\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 0.9999979734420776\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-3.9814)\n",
      "111 |　Epoch 0 | Target Class 0 | Current Logits for target class 1.318504655500874e-05\n",
      "Epoch 25 | Target Class 0 | Current Logits for target class 0.7487655878067017\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 0.9999916553497314\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-0.8927)\n",
      "127 |　Epoch 0 | Target Class 0 | Current Logits for target class 9.468387335501561e-16\n",
      "Epoch 133 | Target Class 0 | Current Logits for target class 0.8684883117675781\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-7.2801)\n",
      "137 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.03013448975980282\n",
      "Epoch 2 | Target Class 0 | Current Logits for target class 0.9999991655349731\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-0.4370)\n",
      "139 |　Epoch 0 | Target Class 0 | Current Logits for target class 9.412565258795898e-24\n",
      "Epoch 143 | Target Class 0 | Current Logits for target class 0.7711541056632996\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-5.5834)\n",
      "198 |　Epoch 0 | Target Class 0 | Current Logits for target class 6.642114375871033e-12\n",
      "Epoch 31 | Target Class 0 | Current Logits for target class 0.9016435742378235\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-4.8644)\n",
      "219 |　Epoch 0 | Target Class 0 | Current Logits for target class 1.4064936010565326e-13\n",
      "Epoch 39 | Target Class 0 | Current Logits for target class 0.8630326390266418\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-6.1760)\n",
      "231 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.0006983298226259649\n",
      "Epoch 15 | Target Class 0 | Current Logits for target class 0.7919860482215881\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(0.4048)\n",
      "241 |　Epoch 0 | Target Class 0 | Current Logits for target class 2.543981361598684e-24\n",
      "Epoch 390 | Target Class 0 | Current Logits for target class 0.5658924579620361\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-3.6619)\n",
      "259 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.01898708939552307\n",
      "Epoch 16 | Target Class 0 | Current Logits for target class 0.8531720042228699\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-3.9890)\n",
      "261 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.0008450262830592692\n",
      "Epoch 29 | Target Class 0 | Current Logits for target class 0.9345503449440002\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(0.3178)\n",
      "263 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.0\n",
      "tensor(2.7748)\n",
      "263 |　Epoch 500 | Target Class 0 | Current Logits for target class 5.522934507503152e-35\n",
      "tensor(-3.0567)\n",
      "263 |　Epoch 1000 | Target Class 0 | Current Logits for target class 9.567828664946272e-25\n",
      "tensor(-2.8354)\n",
      "263 |　Epoch 1500 | Target Class 0 | Current Logits for target class 8.178972974203868e-22\n",
      "tensor(-1.4815)\n",
      "263 |　Epoch 2000 | Target Class 0 | Current Logits for target class 1.735441824968209e-11\n",
      "tensor(-0.9719)\n",
      "263 |　Epoch 2500 | Target Class 0 | Current Logits for target class 1.1160419489897322e-05\n",
      "tensor(-0.8549)\n",
      "263 |　Epoch 3000 | Target Class 0 | Current Logits for target class 0.00025015859864652157\n",
      "Epoch 3112 | Target Class 0 | Current Logits for target class 0.8876693248748779\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 0.999789297580719\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-0.0232)\n",
      "277 |　Epoch 0 | Target Class 0 | Current Logits for target class 4.035739577255473e-43\n",
      "Epoch 422 | Target Class 0 | Current Logits for target class 0.8851180672645569\n",
      "tensor(-6.2990)\n",
      "278 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.009442443028092384\n",
      "Epoch 10 | Target Class 0 | Current Logits for target class 0.8503910899162292\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-0.4608)\n",
      "302 |　Epoch 0 | Target Class 0 | Current Logits for target class 6.593517832415019e-12\n",
      "Epoch 95 | Target Class 0 | Current Logits for target class 0.7209649085998535\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-4.9797)\n",
      "325 |　Epoch 0 | Target Class 0 | Current Logits for target class 3.595941961975768e-07\n",
      "Epoch 9 | Target Class 0 | Current Logits for target class 0.833416759967804\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-4.2776)\n",
      "361 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.3352581560611725\n",
      "Epoch 4 | Target Class 0 | Current Logits for target class 0.7786549925804138\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 0.768159806728363\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-0.0155)\n",
      "390 |　Epoch 0 | Target Class 0 | Current Logits for target class 1.3551537124273156e-19\n",
      "tensor(0.5110)\n",
      "390 |　Epoch 500 | Target Class 0 | Current Logits for target class 3.372246704103077e-09\n",
      "tensor(0.4870)\n",
      "390 |　Epoch 1000 | Target Class 0 | Current Logits for target class 6.84951999119221e-07\n",
      "tensor(0.5583)\n",
      "390 |　Epoch 1500 | Target Class 0 | Current Logits for target class 7.166850991779938e-05\n",
      "tensor(0.0142)\n",
      "390 |　Epoch 2000 | Target Class 0 | Current Logits for target class 0.003680115332826972\n",
      "tensor(-0.0004)\n",
      "390 |　Epoch 2500 | Target Class 0 | Current Logits for target class 0.0055143763311207294\n",
      "tensor(-0.0004)\n",
      "390 |　Epoch 3000 | Target Class 0 | Current Logits for target class 0.008466043509542942\n",
      "tensor(0.0394)\n",
      "390 |　Epoch 3500 | Target Class 0 | Current Logits for target class 0.01434941403567791\n",
      "tensor(-0.0004)\n",
      "390 |　Epoch 4000 | Target Class 0 | Current Logits for target class 0.026866568252444267\n",
      "tensor(0.0378)\n",
      "390 |　Epoch 4500 | Target Class 0 | Current Logits for target class 0.05443296581506729\n",
      "Epoch 5000 | Target Class 0 | Current Logits for target class 0.11326685547828674\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 0.9999992847442627\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-4.5875)\n",
      "415 |　Epoch 0 | Target Class 0 | Current Logits for target class 1.066333111220119e-12\n",
      "Epoch 34 | Target Class 0 | Current Logits for target class 0.9534556865692139\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(0.0248)\n",
      "436 |　Epoch 0 | Target Class 0 | Current Logits for target class 0.0\n",
      "tensor(-0.4540)\n",
      "436 |　Epoch 500 | Target Class 0 | Current Logits for target class 0.0\n",
      "tensor(-0.8018)\n",
      "436 |　Epoch 1000 | Target Class 0 | Current Logits for target class 0.0\n",
      "tensor(-0.4680)\n",
      "436 |　Epoch 1500 | Target Class 0 | Current Logits for target class 2.6624670822171524e-44\n",
      "tensor(-0.4042)\n",
      "436 |　Epoch 2000 | Target Class 0 | Current Logits for target class 2.6316048848388627e-38\n",
      "tensor(-0.3025)\n",
      "436 |　Epoch 2500 | Target Class 0 | Current Logits for target class 1.2001967217563448e-34\n",
      "tensor(-0.4469)\n",
      "436 |　Epoch 3000 | Target Class 0 | Current Logits for target class 1.3922340680969583e-30\n",
      "tensor(-0.4316)\n",
      "436 |　Epoch 3500 | Target Class 0 | Current Logits for target class 2.0870313649705038e-26\n",
      "tensor(-0.3066)\n",
      "436 |　Epoch 4000 | Target Class 0 | Current Logits for target class 2.6594596329564575e-22\n",
      "tensor(-0.5808)\n",
      "436 |　Epoch 4500 | Target Class 0 | Current Logits for target class 1.4062010856397367e-17\n",
      "Epoch 5000 | Target Class 0 | Current Logits for target class 0.00010938480409095064\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(-5.1484)\n",
      "472 |　Epoch 0 | Target Class 0 | Current Logits for target class 6.91470677338657e-06\n",
      "Epoch 24 | Target Class 0 | Current Logits for target class 0.6532790064811707\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 0.9885159730911255\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "Epoch 0 | Target Class 0 | Current Logits for target class 1.0\n",
      "tensor(103.2034)\n",
      "0 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 124 | Target Class 1 | Current Logits for target class 0.9776431918144226\n",
      "tensor(57.2959)\n",
      "1 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 212 | Target Class 1 | Current Logits for target class 0.689950704574585\n",
      "tensor(31.4650)\n",
      "2 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 197 | Target Class 1 | Current Logits for target class 0.834689199924469\n",
      "tensor(29.1575)\n",
      "3 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 80 | Target Class 1 | Current Logits for target class 0.9433228373527527\n",
      "tensor(76.0878)\n",
      "4 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 151 | Target Class 1 | Current Logits for target class 0.8793452382087708\n",
      "tensor(68.9457)\n",
      "5 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "tensor(41.2115)\n",
      "5 |　Epoch 500 | Target Class 1 | Current Logits for target class 2.9064455703275982e-11\n",
      "Epoch 582 | Target Class 1 | Current Logits for target class 0.8515781164169312\n",
      "tensor(107.0959)\n",
      "6 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 82 | Target Class 1 | Current Logits for target class 0.5935835242271423\n",
      "tensor(56.3252)\n",
      "7 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "tensor(43.2063)\n",
      "7 |　Epoch 500 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 683 | Target Class 1 | Current Logits for target class 0.867167592048645\n",
      "tensor(83.4529)\n",
      "8 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 196 | Target Class 1 | Current Logits for target class 0.7175023555755615\n",
      "tensor(62.6340)\n",
      "9 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 228 | Target Class 1 | Current Logits for target class 0.9259885549545288\n",
      "tensor(54.6828)\n",
      "10 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 199 | Target Class 1 | Current Logits for target class 0.6507256627082825\n",
      "tensor(37.4219)\n",
      "11 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 481 | Target Class 1 | Current Logits for target class 0.8010205030441284\n",
      "tensor(20.9166)\n",
      "12 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 57 | Target Class 1 | Current Logits for target class 0.8902685642242432\n",
      "tensor(98.7259)\n",
      "13 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 395 | Target Class 1 | Current Logits for target class 0.8921345472335815\n",
      "tensor(94.0458)\n",
      "14 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 360 | Target Class 1 | Current Logits for target class 0.8405230045318604\n",
      "tensor(20.6162)\n",
      "15 |　Epoch 0 | Target Class 1 | Current Logits for target class 5.439361571474094e-28\n",
      "Epoch 24 | Target Class 1 | Current Logits for target class 0.9425658583641052\n",
      "tensor(27.9858)\n",
      "16 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 68 | Target Class 1 | Current Logits for target class 0.9302570819854736\n",
      "tensor(55.9677)\n",
      "17 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 111 | Target Class 1 | Current Logits for target class 0.8747174143791199\n",
      "tensor(47.5392)\n",
      "18 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 80 | Target Class 1 | Current Logits for target class 0.9401031136512756\n",
      "tensor(96.9118)\n",
      "19 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 80 | Target Class 1 | Current Logits for target class 0.9287689924240112\n",
      "tensor(53.1667)\n",
      "20 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 95 | Target Class 1 | Current Logits for target class 0.9999916553497314\n",
      "tensor(65.3287)\n",
      "21 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 194 | Target Class 1 | Current Logits for target class 0.8273218870162964\n",
      "tensor(100.5885)\n",
      "22 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 180 | Target Class 1 | Current Logits for target class 0.9987121820449829\n",
      "tensor(51.7644)\n",
      "23 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 97 | Target Class 1 | Current Logits for target class 0.7705672979354858\n",
      "tensor(24.7189)\n",
      "24 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 47 | Target Class 1 | Current Logits for target class 0.703269362449646\n",
      "tensor(89.8750)\n",
      "25 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 114 | Target Class 1 | Current Logits for target class 0.7141423225402832\n",
      "tensor(22.0965)\n",
      "26 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 142 | Target Class 1 | Current Logits for target class 0.939775288105011\n",
      "tensor(52.1311)\n",
      "27 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 115 | Target Class 1 | Current Logits for target class 0.9705087542533875\n",
      "tensor(19.5057)\n",
      "28 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 89 | Target Class 1 | Current Logits for target class 0.8436446785926819\n",
      "tensor(70.1862)\n",
      "29 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 64 | Target Class 1 | Current Logits for target class 0.9931588768959045\n",
      "tensor(31.7242)\n",
      "30 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 76 | Target Class 1 | Current Logits for target class 0.7641705274581909\n",
      "tensor(62.8266)\n",
      "31 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 144 | Target Class 1 | Current Logits for target class 0.930916965007782\n",
      "tensor(27.2789)\n",
      "32 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 192 | Target Class 1 | Current Logits for target class 0.728255569934845\n",
      "tensor(51.4414)\n",
      "33 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 108 | Target Class 1 | Current Logits for target class 0.8995240926742554\n",
      "tensor(39.8511)\n",
      "34 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "tensor(40.9051)\n",
      "34 |　Epoch 500 | Target Class 1 | Current Logits for target class 1.9351931792325724e-42\n",
      "Epoch 867 | Target Class 1 | Current Logits for target class 0.9819740056991577\n",
      "tensor(39.2973)\n",
      "35 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 313 | Target Class 1 | Current Logits for target class 1.0\n",
      "tensor(85.1012)\n",
      "36 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 102 | Target Class 1 | Current Logits for target class 0.9963514804840088\n",
      "tensor(67.4418)\n",
      "37 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 336 | Target Class 1 | Current Logits for target class 0.9072428941726685\n",
      "Epoch 0 | Target Class 1 | Current Logits for target class 1.0\n",
      "tensor(60.4505)\n",
      "39 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 245 | Target Class 1 | Current Logits for target class 0.6443055272102356\n",
      "tensor(78.3341)\n",
      "40 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 67 | Target Class 1 | Current Logits for target class 0.9401747584342957\n",
      "tensor(37.3520)\n",
      "41 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 92 | Target Class 1 | Current Logits for target class 0.9812428951263428\n",
      "tensor(100.9890)\n",
      "42 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 80 | Target Class 1 | Current Logits for target class 0.9937697052955627\n",
      "tensor(36.8071)\n",
      "43 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 61 | Target Class 1 | Current Logits for target class 0.9516332149505615\n",
      "tensor(45.0544)\n",
      "44 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 155 | Target Class 1 | Current Logits for target class 1.0\n",
      "tensor(32.6786)\n",
      "45 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 157 | Target Class 1 | Current Logits for target class 0.7619587182998657\n",
      "tensor(58.2331)\n",
      "46 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 101 | Target Class 1 | Current Logits for target class 0.9348576068878174\n",
      "tensor(12.3877)\n",
      "47 |　Epoch 0 | Target Class 1 | Current Logits for target class 2.668671030227833e-19\n",
      "Epoch 45 | Target Class 1 | Current Logits for target class 0.7477245926856995\n",
      "tensor(60.3484)\n",
      "48 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 116 | Target Class 1 | Current Logits for target class 0.9733388423919678\n",
      "tensor(28.6744)\n",
      "49 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 78 | Target Class 1 | Current Logits for target class 0.9280804991722107\n",
      "tensor(22.3284)\n",
      "50 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 66 | Target Class 1 | Current Logits for target class 0.8061662316322327\n",
      "tensor(44.6602)\n",
      "51 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 118 | Target Class 1 | Current Logits for target class 0.6783552169799805\n",
      "tensor(70.2159)\n",
      "52 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 88 | Target Class 1 | Current Logits for target class 0.8460507988929749\n",
      "tensor(24.4295)\n",
      "53 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 35 | Target Class 1 | Current Logits for target class 0.799269437789917\n",
      "tensor(94.3162)\n",
      "54 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 120 | Target Class 1 | Current Logits for target class 0.9665701389312744\n",
      "Epoch 0 | Target Class 1 | Current Logits for target class 1.0\n",
      "tensor(48.6606)\n",
      "56 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 106 | Target Class 1 | Current Logits for target class 0.9931061863899231\n",
      "tensor(62.4704)\n",
      "57 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 95 | Target Class 1 | Current Logits for target class 0.9839197993278503\n",
      "tensor(97.8400)\n",
      "58 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 85 | Target Class 1 | Current Logits for target class 0.8883886337280273\n",
      "tensor(71.3518)\n",
      "59 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "tensor(75.9567)\n",
      "59 |　Epoch 500 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 751 | Target Class 1 | Current Logits for target class 0.9902341365814209\n",
      "tensor(67.4713)\n",
      "60 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 96 | Target Class 1 | Current Logits for target class 0.9736358523368835\n",
      "tensor(49.5220)\n",
      "61 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 130 | Target Class 1 | Current Logits for target class 0.8216173648834229\n",
      "tensor(32.6152)\n",
      "62 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 51 | Target Class 1 | Current Logits for target class 0.5993971824645996\n",
      "tensor(26.8441)\n",
      "63 |　Epoch 0 | Target Class 1 | Current Logits for target class 3.853570776893247e-42\n",
      "Epoch 40 | Target Class 1 | Current Logits for target class 0.7915096282958984\n",
      "tensor(50.4865)\n",
      "64 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 95 | Target Class 1 | Current Logits for target class 0.9950610995292664\n",
      "tensor(17.2495)\n",
      "65 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 45 | Target Class 1 | Current Logits for target class 0.561767041683197\n",
      "tensor(41.6689)\n",
      "66 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 68 | Target Class 1 | Current Logits for target class 0.8304572105407715\n",
      "tensor(67.2078)\n",
      "67 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 88 | Target Class 1 | Current Logits for target class 0.9102996587753296\n",
      "tensor(39.9497)\n",
      "68 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 76 | Target Class 1 | Current Logits for target class 0.9823049306869507\n",
      "tensor(13.1085)\n",
      "69 |　Epoch 0 | Target Class 1 | Current Logits for target class 2.2071913071147634e-16\n",
      "Epoch 34 | Target Class 1 | Current Logits for target class 0.7534241676330566\n",
      "tensor(45.9548)\n",
      "70 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 72 | Target Class 1 | Current Logits for target class 0.9571800231933594\n",
      "tensor(61.0420)\n",
      "71 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 397 | Target Class 1 | Current Logits for target class 0.6312640309333801\n",
      "tensor(103.6943)\n",
      "72 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 130 | Target Class 1 | Current Logits for target class 0.9688497185707092\n",
      "tensor(78.2563)\n",
      "73 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 92 | Target Class 1 | Current Logits for target class 0.863049328327179\n",
      "tensor(37.6620)\n",
      "74 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 70 | Target Class 1 | Current Logits for target class 0.9166632294654846\n",
      "tensor(37.4945)\n",
      "75 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 75 | Target Class 1 | Current Logits for target class 0.7774530649185181\n",
      "tensor(21.7891)\n",
      "76 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n",
      "Epoch 92 | Target Class 1 | Current Logits for target class 0.8843111991882324\n",
      "tensor(116.0171)\n",
      "77 |　Epoch 0 | Target Class 1 | Current Logits for target class 0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "print(\"Class impression generation finished!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class impression generation finished!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## New idea: complete graph with edge feature as probability of edge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for every class, generate certain amount of class imporessions\n",
    "for cur_class in range(dataset.num_classes):\n",
    "    # update class impressions individually\n",
    "    for idx in range(500):\n",
    "        \n",
    "        # create an random adjacency matrix for given nodes & labels\n",
    "        num_nodes = random.randint(1, 600)\n",
    "        sample = geo.data.Batch()\n",
    "        adv_adj = torch.ones(size=(num_nodes, num_nodes), device=args.device).bool()\n",
    "        sample.edge_index = geo.utils.remove_self_loops(adj2idx(adv_adj).long())[0]\n",
    "        sample.x = getNodes(num_nodes)\n",
    "        sample.edge_attr = torch.rand(sample.edge_index.shape[1], ).to(args.device)\n",
    "        sample.edge_attr.requires_grad_()\n",
    "#         sample.to(args.device)\n",
    "        \n",
    "        cl_optim = torch.optim.Adam([sample.edge_attr], lr=0.1)\n",
    "        cur_pred = model(sample)\n",
    "        cur_pred = getOutput(cur_pred)\n",
    "        cur_tar = random.uniform(0.55, 0.99)\n",
    "        cnt = 0\n",
    "        while F.softmax(cur_pred)[:, cur_class].item() < cur_tar and cnt < 5000: # cur_tar:\n",
    "            cl_optim.zero_grad()\n",
    "            cur_pred = getOutput(model(sample))\n",
    "            # loss = cl_lossfunc(cur_pred, cur_class)\n",
    "            # loss = dif_trans_lossfunc(loaded_model, cls_impr, cur_class)\n",
    "            loss = F.nll_loss(cur_pred, torch.Tensor([cur_class]).long().to(args.device))\n",
    "            loss.backward()\n",
    "            cl_optim.step()\n",
    "#             if cnt % 500 == 0:\n",
    "#                 print(sample.edge_attr.grad.sum())\n",
    "#                 print('{} |　Epoch {} | Target Class {} | Current Logits for target class {}'.format(\n",
    "#                     idx, cnt, cur_class, F.softmax(cur_pred)[0,cur_class].item()))\n",
    "            cnt += 1\n",
    "            with torch.no_grad():\n",
    "                sample.edge_attr.clamp_(0, 1)\n",
    "#             print(F.softmax(cur_pred), F.softmax(cur_pred)[:, cur_class], cur_tar)\n",
    "        sample = geo.data.Data(x=sample.x, edge_attr=sample.edge_attr, edge_index=sample.edge_index, y=torch.Tensor([cur_class]).long())\n",
    "        torch.save(sample, os.path.join('data', dataset_name, 'classImpression', str(cur_class)+'_tropology', '{}.pt'.format(idx)))\n",
    "#         print('Epoch {} | Target Class {} | Current Logits for target class {}'.format(\n",
    "#                     cnt, cur_class, F.softmax(cur_pred)[0,cur_class].item()))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of graph_AAA.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/ScottLiao920/FYP/blob/master/graph_AAA.ipynb",
     "timestamp": 1608793297259
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}