{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.io as sio\n",
    "import kornia\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL2Ten = torchvision.transforms.ToTensor()\n",
    "Ten2PIL = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_name, root, train, download, transform, target_transform=None):\n",
    "        super(TensorDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        if dataset_name.lower() == 'mnist':\n",
    "            self.dataset = torchvision.datasets.MNIST(root=root, train=train, download=download)\n",
    "        elif dataset_name.lower() == 'fmnist':\n",
    "            self.dataset = torchvision.datasets.FashionMNIST(root=root, train=train, download=download)\n",
    "        elif dataset_name.lower() == 'stl10':\n",
    "            split_name = 'train' if train == True else 'test'\n",
    "            self.dataset = torchvision.datasets.STL10(root=root, split=split_name, download=download)\n",
    "        elif dataset_name.lower() == 'cifar10':\n",
    "            self.dataset = torchvision.datasets.CIFAR10(root=root, train=train, download=download)\n",
    "        elif dataset_name.lower() == 'cifar100':\n",
    "            self.dataset = torchvision.datasets.CIFAR100(root=root, train=train, download=download)      \n",
    "        elif dataset_name.lower() == 'imagenet':\n",
    "            self.dataset = torchvision.datasets.ImageFolder(os.path.join('data', 'ILSVRC2012', 'train' if train else 'val'))\n",
    "            self.transform = torchvision.transforms.Compose(\n",
    "                [torchvision.transforms.Resize((224, 224)), transform]\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only MNIST, FashionMNIST(fmnist) and STL10 supported for now!\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.__len__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pil_img, label = self.dataset[index]\n",
    "        return (self.transform(pil_img), torch.Tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(dataset_name):\n",
    "    if dataset_name.lower() in ['mnist' , 'fmnist']:\n",
    "        model = nn.Sequential(nn.Conv2d(1, 16, 3),\n",
    "                            nn.BatchNorm2d(16),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(2),\n",
    "                             \n",
    "                            nn.Conv2d(16, 32, 3),\n",
    "                            nn.BatchNorm2d(32),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(2),\n",
    "                             \n",
    "                            nn.Conv2d(32, 64, 2),\n",
    "                            nn.BatchNorm2d(64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(2),\n",
    "                            \n",
    "                            nn.Flatten(),\n",
    "                            nn.Dropout(0.5),\n",
    "                            nn.Linear(64*2*2, 64),\n",
    "                            nn.Linear(64, 10)\n",
    "                            )\n",
    "    elif dataset_name.lower() in ['stl10', 'cifar10', 'cifar100']:\n",
    "        model = torchvision.models.vgg11_bn(num_classes=10)\n",
    "    elif dataset_name.lower() in ['imagenet']:\n",
    "        model = torchvision.models.vgg19_bn(pretrained=True)\n",
    "        # model = nn.Sequential(\n",
    "        #     nn.Conv2d(3, 64, 11, 4, padding=0),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.LocalResponseNorm(size=5, k=2),\n",
    "        #     nn.MaxPool2d(2), \n",
    "\n",
    "        #     nn.Conv2d(64, 256, 5, 1, padding=2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.LocalResponseNorm(size=5, k=2),\n",
    "        #     nn.MaxPool2d(2),\n",
    "\n",
    "        #     nn.Conv2d(256, 256, 3, 1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "\n",
    "        #     nn.Conv2d(256, 256, 3, 1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "\n",
    "        #     nn.Conv2d(256, 256, 3, 1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2),\n",
    "\n",
    "        #     nn.Flatten(),\n",
    "\n",
    "        #     nn.Linear(256 * 6 * 6, 4096),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Dropout(),\n",
    "        #     nn.Linear(4096, 4096),\n",
    "        #     nn.ReLU(True),\n",
    "        #     nn.Dropout(),\n",
    "        #     nn.Linear(4096, 1000)\n",
    "        # ) # VGG-F as in original AAA paper\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only MNIST, FashionMNIST, CIFAR and STL10 datasets supported!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(in_features=10, out_features=16)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 3, 5, stride=2),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(3, 3, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(3, 3, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(3, 3, 3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(3, 3, 3, stride=2)\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 1, 3, stride=2),\n",
    "            nn.Conv2d(1, 1, 3, stride=2),\n",
    "            nn.Conv2d(1, 1, 3, stride=2),\n",
    "            nn.Conv2d(1, 1, 3, stride=2),\n",
    "            nn.Conv2d(1, 1, 5, stride=2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "#         feat = self.lin(x).reshape(-1, 1, 4, 4)\n",
    "#         return self.deconv(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(torch.zeros((1, 3, 128, 128))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
